{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text generation with Gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8N6faiObmLZdWXzbSxZPt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSabbar/Generation-lyrics-PNL/blob/master/Text_generation_with_Gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0F0UKxaoty2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "import re\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHmTGOfcpEBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Get_soup_bs4(url):\n",
        "    requete = requests.get(url)\n",
        "    page = requete.content\n",
        "    soup = BeautifulSoup(page, 'html.parser')\n",
        "    return soup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SfYa31sqJ2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_between(s, first, last ):\n",
        "    try:\n",
        "        start = s.index( first ) + len( first )\n",
        "        end = s.index( last, start )\n",
        "        return s[start:end]\n",
        "    except ValueError:\n",
        "        return \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmusu7CFfpVR",
        "colab_type": "code",
        "outputId": "42c52158-4400-40ea-c409-342c526414c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8P14kVrdF9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "# soup = Get_soup_bs4('https://genius.com/albums/Pnl/Deux-freres')\n",
        "# soup = Get_soup_bs4('https://genius.com/albums/Pnl/Dans-la-legende')\n",
        "# soup = Get_soup_bs4('https://genius.com/albums/Pnl/Le-monde-chico')\n",
        "soup = Get_soup_bs4('https://genius.com/albums/Pnl/Que-la-famille')\n",
        "\n",
        "urls = []\n",
        "for url in soup.find_all('a'):\n",
        "  track = find_between(url.get('href'), 'https://genius.com/Pnl-', '-lyrics')\n",
        "  if track:\n",
        "    #print(url.get('href'))\n",
        "    urls.append(url.get('href'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvrkPvwCpIof",
        "colab_type": "code",
        "outputId": "aef152fa-a919-4004-f575-528beb74c6b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "urls, len(urls)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['https://genius.com/Pnl-je-vis-je-visser-lyrics',\n",
              "  'https://genius.com/Pnl-lala-lyrics',\n",
              "  'https://genius.com/Pnl-differents-lyrics',\n",
              "  'https://genius.com/Pnl-obliges-de-prendre-lyrics',\n",
              "  'https://genius.com/Pnl-de-la-fenetre-au-ter-ter-lyrics',\n",
              "  'https://genius.com/Pnl-pnl-lyrics',\n",
              "  'https://genius.com/Pnl-jcomprends-pas-lyrics',\n",
              "  'https://genius.com/Pnl-gala-gala-lyrics',\n",
              "  'https://genius.com/Pnl-la-petite-voix-lyrics',\n",
              "  'https://genius.com/Pnl-athena-lyrics',\n",
              "  'https://genius.com/Pnl-recherche-du-bonheur-lyrics',\n",
              "  'https://genius.com/Pnl-simba-lyrics',\n",
              "  'https://genius.com/Pnl-de-la-fenetre-au-ter-ter-lyrics',\n",
              "  'https://genius.com/Pnl-athena-lyrics'],\n",
              " 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFzI9pu9pIe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for url in urls:\n",
        "  soup_ = Get_soup_bs4(url)\n",
        "  for i, texte in enumerate(soup_.find_all('p')):\n",
        "    if i == 0: \n",
        "      #All_texte.append(texte.text)\n",
        "      with open('/content/gdrive/My Drive/Colab Notebooks/PNL-DL/data/Que-la-famille/' + find_between(url, 'Pnl-', '-lyrics') + \".txt\", \"w\") as text_file:\n",
        "        text_file.write(texte.text)\n",
        "    else :\n",
        "      pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNxJNuPQmbJT",
        "colab_type": "code",
        "outputId": "67cf8af6-8186-4a38-b82a-bb2cd4c2e77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip3 install pathlib2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pathlib2\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/45/9c82d3666af4ef9f221cbb954e1d77ddbb513faf552aea6df5f37f1a4859/pathlib2-2.3.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pathlib2) (1.12.0)\n",
            "Installing collected packages: pathlib2\n",
            "Successfully installed pathlib2-2.3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8knc9CnwlsOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib2 import Path\n",
        "def get_ref_files(path : str):\n",
        "    all_objects = Path(path).glob('**/*.txt')\n",
        "    files = [str(p) for p in all_objects if p.is_file()]\n",
        "    return files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc3COAfvfmrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "REPLACE_NO_CHAR_SPACE = re.compile(r\"[-_&;!=\\%?\\\"()\\\\]\")\n",
        "\n",
        "def load_data(fname):\n",
        "    with open(fname, 'r') as f:\n",
        "        text = f.read()\n",
        "    text = REPLACE_NO_CHAR_SPACE.sub(' ', text.lower())\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    data = text.split()\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKKaacTwfn6z",
        "colab_type": "code",
        "outputId": "0be2dd7b-3a41-4091-f5fd-929c5a2ae477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path_data = '/content/gdrive/My Drive/Colab Notebooks/PNL-DL/data/'\n",
        "text = []\n",
        "for path in get_ref_files(path_data) :\n",
        "  text += load_data(path)\n",
        "\n",
        "len(get_ref_files(path_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RvHQ7lK0nmM",
        "colab_type": "code",
        "outputId": "688ba3b3-7cc4-42ad-ec0f-6172e94edc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "text[:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[couplet',\n",
              " '1',\n",
              " 'ademo]',\n",
              " 'ma',\n",
              " 'frappe',\n",
              " \"y'a\",\n",
              " 'personne',\n",
              " 'qui',\n",
              " 'l’arrête',\n",
              " 'penalty',\n",
              " \"j'souris\",\n",
              " 'au',\n",
              " 'gardien',\n",
              " 'igo',\n",
              " \"y'a\",\n",
              " 'mowgli',\n",
              " 'dans',\n",
              " 'l’arène',\n",
              " 'ciseaux,',\n",
              " 'retournée']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9jJZpt0glgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set(text)\n",
        "vocab_to_int = {w: idx for idx, w in enumerate(vocab)}\n",
        "int_to_vocab = {idx: w for idx, w in enumerate(vocab)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE2k9cERnaVi",
        "colab_type": "code",
        "outputId": "bbb5825e-ed2a-4f04-9f63-d71923dd887d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Total words: {}'.format(len(text)))\n",
        "print('Vocab size: {}'.format(len(vocab)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words: 35027\n",
            "Vocab size: 6617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZomwZTaNhGkJ",
        "colab_type": "text"
      },
      "source": [
        "Convertir le texte en nombre entier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u087X8t_g6im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_text = [vocab_to_int[w] for w in text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E4-PIJThK0R",
        "colab_type": "code",
        "outputId": "0abeb01c-773a-48ab-aa83-7b0ca0f89949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from distutils.version import LooseVersion\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEj4x-qwhMx8",
        "colab_type": "code",
        "outputId": "5f760ed5-8084-4af0-dc03-69d28411214a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
        "print('TensorFlow version : {}'.format(tf.__version__))\n",
        "\n",
        "# GPU\n",
        "if not tf.test.gpu_device_name():\n",
        "    warnings.warn('Aucun GPU trouvé, utilisez le GPU pour la projet!')\n",
        "else:\n",
        "    print('Périphérique GPU par défaut: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version : 1.15.0\n",
            "Périphérique GPU par défaut: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tECuPvKRh7Qp",
        "colab_type": "text"
      },
      "source": [
        "Couche d'entrée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdwnbTjRhRjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_inputs():\n",
        "    '''\n",
        "    Création de la couche d'entrée\n",
        "    '''\n",
        "    inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
        "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
        "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
        "    return inputs, targets, learning_rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rukf_k9jiL-n",
        "colab_type": "text"
      },
      "source": [
        "RNN Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ZC31bFiFwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_init_cell(batch_size, rnn_size):\n",
        "    '''\n",
        "    Construire des unités RNN empilées\n",
        "    \n",
        "    Paramètre\n",
        "    ---\n",
        "    batch_size: La taille de chaque batch\n",
        "    rnn_size: Nombre de neurones cachés dans RNN\n",
        "    '''\n",
        "    lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
        "    cell = tf.contrib.rnn.MultiRNNCell([lstm])\n",
        "    \n",
        "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
        "    initial_state = tf.identity(initial_state, 'initial_state')\n",
        "    return cell, initial_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuE7tAoUigVq",
        "colab_type": "text"
      },
      "source": [
        "Word Embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIdcU8nQieZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_embed(input_data, vocab_size, embed_dim):\n",
        "    '''\n",
        "     bcp de mots doivent être intégrés en embedding\n",
        "     ---\n",
        "     input_data: tenseur d'entrée\n",
        "     vocab_size: taille du vocabulaire\n",
        "     embed_dim: dimension d'intégration\n",
        "     '''\n",
        "    embedding = tf.Variable(tf.random_uniform([vocab_size, embed_dim], -1, 1))\n",
        "    embed = tf.nn.embedding_lookup(embedding, input_data)\n",
        "    \n",
        "    return embed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Raq3xAiXi6xo",
        "colab_type": "text"
      },
      "source": [
        "Build RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M51scwGzizKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_rnn(cell, inputs):\n",
        "    '''\n",
        "    Construire un modèle RNN\n",
        "    \n",
        "     Paramètres:\n",
        "     ---\n",
        "     cellule: cellule RNN\n",
        "     entrées: lot d'entrée\n",
        "    '''\n",
        "    outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n",
        "    \n",
        "    final_state = tf.identity(final_state, 'final_state')\n",
        "    return outputs, final_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLfHpYUOjNn7",
        "colab_type": "text"
      },
      "source": [
        "Build Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwkynNKMjKIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_nn(cell, rnn_size, input_data, vocab_size, embed_dim):\n",
        "    '''\n",
        "    Construire un réseau de neurones qui connecte la couche RNN à la couche entièrement connectée\n",
        "    \n",
        "     Paramètres:\n",
        "     ---\n",
        "     cellule: cellule RNN\n",
        "     rnn_size: nombre de nœuds RNN cachés\n",
        "     input_data: tenseur d'entrée\n",
        "     vocab_size\n",
        "     embed_dim: incorporer la taille du calque\n",
        "    \n",
        "    '''\n",
        "    embed = get_embed(input_data, vocab_size, embed_dim)\n",
        "    outputs, final_state = build_rnn(cell, embed)\n",
        "    \n",
        "    logits = tf.contrib.layers.fully_connected(outputs, vocab_size, activation_fn=None)\n",
        "    \n",
        "    return logits, final_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWDnNvmLjh0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(int_text, batch_size, seq_length):\n",
        "    '''\n",
        "    Construire batch\n",
        "    '''\n",
        "    batch = batch_size * seq_length\n",
        "    n_batch = len(int_text) // batch\n",
        "    \n",
        "    int_text = np.array(int_text[:batch * n_batch]) # Conserver le numéro qui compose un lot complet\n",
        "    \n",
        "    int_text_targets = np.zeros_like(int_text)\n",
        "    int_text_targets[:-1], int_text_targets[-1] = int_text[1:], int_text[0]\n",
        "    \n",
        "    # Split\n",
        "    x = np.split(int_text.reshape(batch_size, -1), n_batch, -1)\n",
        "    y = np.split(int_text_targets.reshape(batch_size, -1), n_batch, -1)\n",
        "    \n",
        "    return np.stack((x, y), axis=1) # Combinaison"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6HQKoELjie0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Number de Epochs\n",
        "num_epochs = 150\n",
        "# Batch Size\n",
        "batch_size = 64\n",
        "# RNN Size\n",
        "rnn_size = 512\n",
        "# Embedding Dimension Size\n",
        "embed_dim = 200\n",
        "# Sequence Length\n",
        "seq_length = 20\n",
        "# Learning Rate\n",
        "learning_rate = 0.01\n",
        "# Afficher les statistiques pour chaque n nombre de batch\n",
        "show_every_n_batches = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6BRFegEjlCq",
        "colab_type": "code",
        "outputId": "4b67fb43-acf0-4758-a73d-b9bca46c1ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "from tensorflow.contrib import seq2seq\n",
        "\n",
        "train_graph = tf.Graph()\n",
        "with train_graph.as_default():\n",
        "    vocab_size = len(int_to_vocab) # vocab_size\n",
        "    input_text, targets, lr = get_inputs() # Tenseur d'entrée\n",
        "    input_data_shape = tf.shape(input_text)\n",
        "    # Initialiser RNN\n",
        "    cell, initial_state = get_init_cell(input_data_shape[0], rnn_size)\n",
        "    logits, final_state = build_nn(cell, rnn_size, input_text, vocab_size, embed_dim)\n",
        "\n",
        "    # La probabilité de couche softmax\n",
        "    probs = tf.nn.softmax(logits, name='probs')\n",
        "\n",
        "    # Fonction de perte\n",
        "    cost = seq2seq.sequence_loss(\n",
        "        logits,\n",
        "        targets,\n",
        "        tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
        "\n",
        "    # Fonction d'optimisation\n",
        "    optimizer = tf.train.AdamOptimizer(lr)\n",
        "\n",
        "    # Gradient Clipping\n",
        "    gradients = optimizer.compute_gradients(cost)\n",
        "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
        "    train_op = optimizer.apply_gradients(capped_gradients)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-59-8fca85706057>:10: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-59-8fca85706057>:11: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-61-2e97e043d937>:10: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECeWHa6-jndZ",
        "colab_type": "code",
        "outputId": "1aec20be-f728-4812-cf01-ca4afaecdb0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "batches = get_batches(int_text, batch_size, seq_length)\n",
        "# Répertoire de stockage des paramètres\n",
        "save_dir = '/content/gdrive/My Drive/Colab Notebooks/alpha-wann-DL/save'\n",
        "\n",
        "with tf.Session(graph=train_graph) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
        "\n",
        "        for batch_i, (x, y) in enumerate(batches):\n",
        "            feed = {\n",
        "                input_text: x,\n",
        "                targets: y,\n",
        "                initial_state: state,\n",
        "                lr: learning_rate}\n",
        "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
        "\n",
        "            # print les résultats à chaque session de formation\n",
        "            if (epoch * len(batches) + batch_i) % show_every_n_batches == 0:\n",
        "                print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
        "                    epoch,\n",
        "                    batch_i,\n",
        "                    len(batches),\n",
        "                    train_loss))\n",
        "    # save le modèle\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess, save_dir)\n",
        "    print('Model Trained and Saved')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch   0 Batch    0/27   train_loss = 8.796\n",
            "Epoch   3 Batch   19/27   train_loss = 2.883\n",
            "Epoch   7 Batch   11/27   train_loss = 0.459\n",
            "Epoch  11 Batch    3/27   train_loss = 0.156\n",
            "Epoch  14 Batch   22/27   train_loss = 0.145\n",
            "Epoch  18 Batch   14/27   train_loss = 0.111\n",
            "Epoch  22 Batch    6/27   train_loss = 0.100\n",
            "Epoch  25 Batch   25/27   train_loss = 0.092\n",
            "Epoch  29 Batch   17/27   train_loss = 0.107\n",
            "Epoch  33 Batch    9/27   train_loss = 0.094\n",
            "Epoch  37 Batch    1/27   train_loss = 0.098\n",
            "Epoch  40 Batch   20/27   train_loss = 0.114\n",
            "Epoch  44 Batch   12/27   train_loss = 0.084\n",
            "Epoch  48 Batch    4/27   train_loss = 0.087\n",
            "Epoch  51 Batch   23/27   train_loss = 0.084\n",
            "Epoch  55 Batch   15/27   train_loss = 0.076\n",
            "Epoch  59 Batch    7/27   train_loss = 0.096\n",
            "Epoch  62 Batch   26/27   train_loss = 0.091\n",
            "Epoch  66 Batch   18/27   train_loss = 0.078\n",
            "Epoch  70 Batch   10/27   train_loss = 0.090\n",
            "Epoch  74 Batch    2/27   train_loss = 0.094\n",
            "Epoch  77 Batch   21/27   train_loss = 0.107\n",
            "Epoch  81 Batch   13/27   train_loss = 0.089\n",
            "Epoch  85 Batch    5/27   train_loss = 0.079\n",
            "Epoch  88 Batch   24/27   train_loss = 0.090\n",
            "Epoch  92 Batch   16/27   train_loss = 4.213\n",
            "Epoch  96 Batch    8/27   train_loss = 3.700\n",
            "Epoch 100 Batch    0/27   train_loss = 2.774\n",
            "Epoch 103 Batch   19/27   train_loss = 2.457\n",
            "Epoch 107 Batch   11/27   train_loss = 1.900\n",
            "Epoch 111 Batch    3/27   train_loss = 1.686\n",
            "Epoch 114 Batch   22/27   train_loss = 1.419\n",
            "Epoch 118 Batch   14/27   train_loss = 1.238\n",
            "Epoch 122 Batch    6/27   train_loss = 1.232\n",
            "Epoch 125 Batch   25/27   train_loss = 1.100\n",
            "Epoch 129 Batch   17/27   train_loss = 1.128\n",
            "Epoch 133 Batch    9/27   train_loss = 0.846\n",
            "Epoch 137 Batch    1/27   train_loss = 0.857\n",
            "Epoch 140 Batch   20/27   train_loss = 0.870\n",
            "Epoch 144 Batch   12/27   train_loss = 0.803\n",
            "Epoch 148 Batch    4/27   train_loss = 0.909\n",
            "Model Trained and Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpfRK4Apj7D2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tensors(loaded_graph):\n",
        "    '''\n",
        "    Obtenir les paramètres des résultats de la formation du modèle\n",
        "\n",
        "    \n",
        "    Paramètre\n",
        "    ---\n",
        "    loaded_graph: Graphique Tensroflow chargé à partir d'un fichier\n",
        "    '''\n",
        "    inputs = loaded_graph.get_tensor_by_name('inputs:0')\n",
        "    initial_state = loaded_graph.get_tensor_by_name('initial_state:0')\n",
        "    final_state = loaded_graph.get_tensor_by_name('final_state:0')\n",
        "    probs = loaded_graph.get_tensor_by_name('probs:0')\n",
        "    return inputs, initial_state, final_state, probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxv7fUp1n4k9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pick_word(probabilities, int_to_vocab):\n",
        "    '''\n",
        "    Sélectionnez des mots pour la génération de texte pour générer le mot suivant avec une certaine probabilité\n",
        "    ---\n",
        "    probabilities: Probabilites du mot suivant\n",
        "    int_to_vocab: Table de cartographie\n",
        "    '''\n",
        "    result = np.random.choice(len(probabilities), 50, p=probabilities)\n",
        "    return int_to_vocab[result[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR8G-3Uzn6Tr",
        "colab_type": "code",
        "outputId": "575593ae-a03e-473d-829e-184ae4dd0574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Longueur du texte généré\n",
        "gen_length = 300\n",
        "\n",
        "# Définir des mots de démarrage à froid\n",
        "prime_word = \"j'veux la maille comme un roi, solo, j'veux ces bitchs\"\n",
        "\n",
        "\n",
        "result = []\n",
        "loaded_graph = tf.Graph()\n",
        "with tf.Session(graph=loaded_graph) as sess:\n",
        "    # Charger le modèle\n",
        "    loader = tf.train.import_meta_graph(save_dir + '.meta')\n",
        "    loader.restore(sess, save_dir)\n",
        "\n",
        "    # Obtenir les paramètres des résultats de l'entraînement\n",
        "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
        "\n",
        "    # Sentences generation setup\n",
        "    gen_sentences = prime_word.split()\n",
        "    #print(gen_sentences)\n",
        "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
        "\n",
        "    # Générer des phrases\n",
        "\n",
        "    for n in range(gen_length):\n",
        "\n",
        "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
        "        dyn_seq_length = len(dyn_input[0])\n",
        "\n",
        "        # Prévision\n",
        "        probabilities, prev_state = sess.run(\n",
        "            [probs, final_state],\n",
        "            {input_text: dyn_input, initial_state: prev_state})\n",
        "\n",
        "        pred_word = pick_word(probabilities[0][dyn_seq_length-1], int_to_vocab) \n",
        "        gen_sentences.append(pred_word)\n",
        "        #print(pred_word)\n",
        "        result.append(pred_word + ' ')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/alpha-wann-DL/save\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DEHqpa6t4aG",
        "colab_type": "code",
        "outputId": "ce5f9d05-0cf5-4b4e-d2cc-3ce524c87bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "lyrics = ''.join(result)\n",
        "lyrics = lyrics.replace(',', '\\n')\n",
        "new_line = []\n",
        "for line in lyrics.split('\\n'):\n",
        "\n",
        "  between = find_between(line, '[', ']')\n",
        "  if between : \n",
        "    ren = line.split('['+between+']')\n",
        "    print(ren[0]+'\\n'+'['+between+']'+'\\n'+ren[1])\n",
        "  else:\n",
        "    for l in line.split():\n",
        "      new_line.append(l)\n",
        "      if len(new_line) > 15:\n",
        "        print(' '.join(new_line) )\n",
        "        new_line = []"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " igo t'es dans la merde dans le benda j'sais que j'm'enfonce plus sur ma gueule veut sa mère la reine un sourire des des doss' des milliers j'veux plus je me va \n",
            "[couplet 1 : n.o.s]\n",
            " si belle la on la merde : faut la défaite n'est ça me faut pas mon égal\n",
            "en j'ai d'la à ta femme viens voir tout à la vie faire au fond d’un\n",
            "hall ça y est a qu'à t'a qu'au drôle d'attitude man a a a abonné a\n",
            "a abonné a a a abonné a a abonné a pas ma putain la p'tite souris\n",
            "cette ‘tasse regarde le temps c'est la vérité j'reprends tu sors à chaque bon char la\n",
            "guerre guerre l'oseille et tout trop vite fait fait j’emballe les miens sont loin qui m'ont\n",
            "du sale j'ai toujours des voit de putes de j lopez de larmes : ma chair\n",
            " le rain ter \n",
            "[couplet 2 : ademo]\n",
            " dans mon igo de ces bâtards\n",
            "vaut ce soir j’sors si de balade ce et en veut encore ouais mon tu connais\n",
            "l'adresse rien dans ma le même que le taga remonté d'malaga sheitana plus veut pas envie\n",
            "d'rigoler pourtant elle la plus la teille que la mif que la mif que la mif\n",
            "que la mif rien n'a changé dans le sourire à une merde faut pas que j'repense\n",
            "au passé sinon rah pour du rap ounga à ton je prends le monde s'active c'est\n",
            "le biff qui m'fait frissonner n'aie fait ouhlalala crime passionnel que j'ai que du biff rien\n",
            "fait la dalle pas ton tel à zoulou tchaing zoulou tchaing zoulou tchaing zoulou tchaing zoulou\n",
            "tchaing zoulou tchaing zoulou tchaing zoulou tchaing j'm'en bats les couilles du trône j'préfère être debout\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKOCeHP-t-sU",
        "colab_type": "code",
        "outputId": "e2e34871-19f2-451c-9973-c03a9c8004e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "lyrics = ''.join(result)\n",
        "lyrics = lyrics.replace(',', '\\n')\n",
        "new_line = []\n",
        "for line in lyrics.split('\\n'):\n",
        "\n",
        "  between = find_between(line, '[', ']')\n",
        "  if between : \n",
        "    ren = line.split('['+between+']')\n",
        "    print(ren[0]+'\\n'+'['+between+']'+'\\n'+ren[1])\n",
        "  else:\n",
        "    for l in line.split():\n",
        "      new_line.append(l)\n",
        "      if len(new_line) > 15:\n",
        "        print(' '.join(new_line) )\n",
        "        new_line = []\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[pont : ademo]\n",
            " chang\n",
            "chang chang j'marche c'est le boule j'ai des fois j't'en veux d'pas avoir été là j'suis\n",
            "plus là pour être honnête double j'ai les depuis cette petite voix on va tout à\n",
            " tout à l'envers \n",
            "[couplet 1 : n.o.s]\n",
            " faut que j'apprenne et pour la hassana le sun me l'odeur d'l'argent ta haine qui m'a apaisé paisé\n",
            "l'envers à l'envers la terre tourne j'me contourne j'vois tout à l'envers paisé pas tes chaînes\n",
            "igo les tits pe moi qui sais c'que j'sais pas j'suis heure pas comme eux pas\n",
            " pas la plus pas là j'fais l'tour la de la fenêtre au ter ter petit frère ira chercher l'oseille de la fenêtre au ter ter \n",
            "[couplet 3 : ademo]\n",
            " j'fume deux frères\n",
            "comme eux pas comme eux le m en l'air dit mon cœur en tu viens manny\n",
            "soit pas pourquoi pas envie d'rigoler quand je t'aime ouais ouais ouais des pédés ou l'argent\n",
            "ouais une y'a rien en essonne toi tu la mif' d'abord c'est quand du bien je\n",
            "suis rassuré ma putain d'tête j'ai de le soir j'ai des hommes le soir j'rentre à\n",
            "la maison j'pose dans les mêmes trous noirs on s'est égarés quand on était pas le\n",
            "temps de la plaine c'est un les billets des frères rentrer pour pas le bon char\n",
            "tout à part j'ai la même même à l'envers juste de la lune car les effets\n",
            "secondaires de travers j'ai pas le temps au temps aux allumettes j'crame soixante juste pour j'veux\n",
            " l j'veux les pieds j'me dis qu'la connaissance mira par vous baise qui \n",
            "[refrain : ademo]\n",
            " salut\n",
            " salut j'suis sans être les gens \n",
            "[refrain : ademo]\n",
            " ok manny\n",
            "du l salut salut salut rebenga dix huit piges sous l’hall j’vends la ganja avec les\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujSiJsIjwxL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}